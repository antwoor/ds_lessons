{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antwoor/ds_lessons/blob/master/%D0%A6%D0%A2%D0%9F%D0%9E_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXqkSJT-a4N4",
        "outputId": "55fd6132-5d96-4770-9cb5-5b1529727885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m705.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56439 sha256=5601f183da5c5f4ddac82d1a4e71754e7ef9c1fe94b7a26254824f2af5affee1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vANRT6ScCc5R"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist # subroutines for fetching the MNIST dataset\n",
        "from keras.models import Model # basic class for specifying and training a neural network\n",
        "from keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
        "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128 # in each iteration, we consider 128 training examples at once\n",
        "num_epochs = 3 # we iterate twenty times over the entire training set\n",
        "hidden_size = 512 # there will be 512 neurons in both hidden layers"
      ],
      "metadata": {
        "id": "g1_PZJqFCdpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 60000 # there are 60000 training examples in MNIST\n",
        "num_test = 10000 # there are 10000 test examples in MNIST\n",
        "\n",
        "height, width, depth = 28, 28, 1 # MNIST images are 28x28 and greyscale\n",
        "num_classes = 10 # there are 10 classes (1 per digit)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() # fetch MNIST data\n",
        "from matplotlib import pyplot\n",
        "for i in range(9):\n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "  pyplot.show()"
      ],
      "metadata": {
        "id": "zsDX0QNqCiBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(num_train, height * width) # Flatten data to 1D\n",
        "X_test = X_test.reshape(num_test, height * width) # Flatten data to 1D\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255 # Normalise data to [0, 1] range\n",
        "X_test /= 255 # Normalise data to [0, 1] range\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
        "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels"
      ],
      "metadata": {
        "id": "0yfX0Ll-GtOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "b9964983-d3cf-4425-dfc3-9b62be603b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9288bcffd003>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;31m# Normalise data to [0, 1] range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# One-hot encode the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# One-hot encode the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'np_utils' has no attribute 'to_categorical'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(height * width,)) # Our input is a 1D vector of size 784\n",
        "hidden_1 = Dense(hidden_size, activation='relu')(inp) # First hidden ReLU layer\n",
        "hidden_2 = Dense(500, activation='relu')(hidden_1) # Second hidden ReLU layer\n",
        "hidden3 =  Dense(500, activation='relu')(hidden_2)\n",
        "soekfosek = Dense(500, activation='relu')(hidden3)\n",
        "out = Dense(num_classes, activation='softmax')(soekfosek) # Output softmax layer\n",
        "\n",
        "model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers"
      ],
      "metadata": {
        "id": "ItIsTKQ5Cmcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
        "              optimizer='adam', # using the Adam optimiser\n",
        "              metrics=['accuracy']) # reporting the accuracy"
      ],
      "metadata": {
        "id": "LWY1ptPoCrVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, # Train the model using the training set...\n",
        "          batch_size=batch_size, epochs=num_epochs,\n",
        "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
        "model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!"
      ],
      "metadata": {
        "id": "17de4NisDMHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_show = model.predict(X_test)"
      ],
      "metadata": {
        "id": "9p6F-VDIDPKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_show"
      ],
      "metadata": {
        "id": "gFTGfc3zNMTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuZKD_OTa53f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}